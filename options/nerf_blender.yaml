_parent_: options/base.yaml

arch:                                                       # architectural options
    layers_feat: [null,256,256,256,256,256,256,256,256]     # hidden layers for feature/density MLP
    layers_rgb: [null,128,3]                                # hidden layers for color MLP
    skip: [4]                                               # skip connections
    posenc:                                                 # positional encoding
        L_3D: 10                                            # number of bases (3D point)
        L_view: 4                                           # number of bases (viewpoint)
    density_activ: softplus                                 # activation function for output volume density
    tf_init: true                                           # initialize network weights in TensorFlow style

nerf:                                                       # NeRF-specific options
    view_dep: true                                          # condition MLP on viewpoint
    depth:                                                  # depth-related options
        param: metric                                       # depth parametrization (for sampling along the ray)
        range: [2,6]                                        # near/far bounds for depth sampling
    sample_intvs: 128                                       # number of samples
    sample_stratified: true                                 # stratified sampling
    fine_sampling: false                                    # hierarchical sampling with another NeRF
    sample_intvs_fine:                                      # number of samples for the fine NeRF
    ray_sampling_strategy: "all_view_rand_rays"             # there are 2 ways to sample pixels ( rays ) during training.
    # it is impossible to render all images at onece, so we just ignore this case in the setting
    # 1.  "all_view_rand_rays" sample random pixels in all view, each view contains same pixel positions.
    # 2.  "single_view_rand_rays" sample random pixels in a single view, each iteration target one view one-by-one.
    n_rays: 1024                                         # number of random rays for each step
    density_noise_reg:                                      # Gaussian noise on density output as regularization
    setbg_opaque: true                                     # fill transparent rendering with known background color (Blender only)

data:                                                       # data options
    dataset: blender                                        # dataset name
    scene: lego                                             # scene name
    image_size: [400,400]                                   # input image sizes [height,width]
    num_workers: 4                                          # number of parallel workers for data loading
    preload: true                                           # preload the entire dataset into the memory
    bgcolor: 1                                              # background color (Blender only)
    val_sub: 4                                              # consider a subset of N validation samples
    test_sub: 20 # the sub-set of test_images that is actually run
    scene_bbox: [-1.5, -1.5, -1.5, 1.5, 1.5, 1.5]

camera:                                                     # camera options
    model: perspective                                      # type of camera model
    ndc: false                                              # reparametrize as normalized device coordinates (NDC)

loss_weight:                                                # loss weights (in log scale)
    render: 0                                               # RGB rendering loss
    render_fine:                                            # RGB rendering loss (for fine NeRF)

optim:                                                      # optimization options
    lr: 5.e-4                                               # learning rate (main)
    lr_end: 1.e-4                                           # terminal learning rate (only used with sched.type=ExponentialLR)
    sched:                                                  # learning rate scheduling options
        type: ExponentialLR                                 # scheduler (see PyTorch doc)
        gamma:                                              # decay rate (can be empty if lr_end were specified)

batch_size:                                                 # batch size (not used for NeRF/BARF)
max_epoch:                                                  # train to maximum number of epochs (not used for NeRF/BARF)
max_iter: 200000                                            # train to maximum number of iterations

trimesh:                                                    # options for marching cubes to extract 3D mesh
    res: 128                                                # 3D sampling resolution
    range: [-1.2,1.2]                                       # 3D range of interest (assuming same for x,y,z)
    thres: 25.                                              # volume density threshold for marching cubes
    chunk_size: 16384                                       # chunk size of dense samples to be evaluated at a time

freq:                                                       # periodic actions during training
    scalar: 200                                             # log losses and scalar states (every N iterations)
    vis: 1000                                               # visualize results (every N iterations)
    val: 2000                                               # validate on val set (every N iterations)
    ckpt: 5000                                              # save checkpoint (every N iterations)
