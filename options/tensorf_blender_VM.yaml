_parent_: options/base.yaml

# --------------------------------------
# tensorf config

visualize_gradient: False

max_iter: 30000                                            # train to maximum number of iterations

train_schedule:
  n_voxel_init: 2097156 # 128**3
  n_voxel_final: 27000000 # 300**3
  upsample_iters: [2000,3000,4000,5500,7000] # iterations for upsampling voxel grid
  update_alphamask_iters: [2000,4000] # iterations for updating alpha mask
  alpha_mask_threshold: 0.0001 # threshold for updating creating alpha mask volume
  shrink_bbox_with_alphamask: true # shrink bbox when first updating alphamask
  resolution_scale_init: [1.0, 1.0, 1.0]


arch:
  shading:
    model: MLP_Fea # can be "SH" or "MLP_PE" or "MLP_Fea" or "MLP" or "RGB"
    view_pe: 2 # positional encoding used for MLP shading model
    pose_pe: 2 # positional encoding used for MLP shading model
    fea_pe: 2 # positional encoding used for MLP shading model
    mlp_hidden_dim: 64 # hidden dimension of MLP shading model
    detach_viewdirs: true
    detach_xyz: true
    app_dim: 27
  feature_to_density_activation: softplus # activation used to convert raw tensor density value to real densoity
  density_shift: -10  # shift density in softplus; making density = 0  when feature == 0
  distance_scale: 25.0 # scale up distance for sigma to alpha computation
  tensorf:
    model: TensorVMSplit # TensorVM Split or TensorCP
    density_components: [16,16,16] # number of tensorf components for density
    color_components: [48,48,48] # number of tensorf components for color
    volume_init_scale: 0.1 # scaling factor for initializing density and feature volume indexes
    volume_init_bias: 0.0
    rayMarch_weight_thres: 0.000001
  # these are unused options
  abs_components: false
  ignore_negative_split: false
  convolve_positive_only: false
  convolve_plane_only: false
  component_wise_feature2density: false
  plane_feature2density: false


loss_weight:                                                # loss weights (in log scale)
    render: 1.0                                               # RGB rendering loss
    render_albedo: 1.0
    render_fine:                                            # RGB rendering loss (for fine NeRF)
    L1: # L1 sparsity loss
      init: 8.e-5 # before first alpha mask update
      rest: 4.e-5 # after first alpha mask update
    TV_density:  0.0 # total variance loss for density components
    TV_color: 0.0 # total variance loss for color components

optim:                                                      # optimization options
    lr_index: 0.02                                              # learning rate (main)
    lr_basis: 1.e-3                                           # terminal learning (only used with sched.type=ExponentialLR)
    lr_decay_target_ratio: 0.1 # the target decay ratio; after decay_iters inital lr decays to lr*ratio
    lr_decay_iters:  -1 #number of iterations the lr will decay to the target ratio; -1 will set it to n_iters
    lr_upsample_reset: true
    algo: Adam # optimizer
    # algo: SGD # Adam doesn't work with float16
    sched: None

#---------------------------------------
# nerf config


nerf:                                                       # NeRF-specific options
    view_dep: true                                          # condition MLP on viewpoint
    depth:                                                  # depth-related options
        param: metric                                       # depth parametrization (for sampling along the ray)
        range: [2,6]                                        # near/far bounds for depth sampling
    sample_intvs: 1000                                     # max number of samples, if set to 1e10 or large number, it means auto adjust
    sample_stratified: true                                 # stratified sampling
    fine_sampling: false                                    # hierarchical sampling with another NeRF
    sample_intvs_fine:                                      # number of samples for the fine NeRF
    ray_sampling_strategy: "all_view_rand_grid"             # there are 2 ways to sample pixels ( rays ) during training.
    # it is impossible to render all images at onece, so we just ignore this case in the setting
    # 1.  "all_view_rand_rays" sample random pixels in all view, each view contains same pixel positions.
    # 2.  "single_view_rand_rays" sample random pixels in a single view, each iteration target one view one-by-one.
    n_rays: 4096                                            # number of random rays for each step
    density_noise_reg:                                      # Gaussian noise on density output as regularization
    setbg_opaque: true                                      # fill transparent rendering with known background color (Blender only)
    step_ratio: 0.5 # ratio between resolution and sampling_step_size
                    # this ratio will compute and estimate sampling interval using current resolution,  overwrite nerf.sample_intvs if smaller
data:                                                       # data options
    dataset: blender                                        # dataset name
    scene: lego                                             # scene name
    image_size: [400,400]                                   # input image sizes [height,width]
    num_workers: 4                                          # number of parallel workers for data loading
    preload: true                                           # preload the entire dataset into the memory
    bgcolor: 1                                              # background color (Blender only)
    val_sub: 10                                              # consider a subset of N validation samples
    test_sub: 200 # num of test image used for evaluation
    scene_bbox: [-1.5, -1.5, -1.5, 1.5, 1.5, 1.5] # [x1,y1,z1,x2,y2,z2]


camera:                                                     # camera options
    model: perspective                                      # type of camera model
    ndc: false                                              # reparametrize as normalized device coordinates (NDC)

                                        # decay rate (can be empty if lr_end were specified)

batch_size:                                                 # batch size (not used for NeRF/BARF)
      # in nerf batchsize ~= nerf.n_rays, and is evenly spread across all poses
max_epoch:                                                  # train to maximum number of epochs (not used for NeRF/BARF)


trimesh:                                                    # options for marching cubes to extract 3D mesh
    res: 128                                                # 3D sampling resolution
    range: [-1.2,1.2]                                       # 3D range of interest (assuming same for x,y,z)
    thres: 25.                                              # volume density threshold for marching cubes
    chunk_size: 16384                                       # chunk size of dense samples to be evaluated at a time

freq:                                                       # periodic actions during training
    scalar: 200                                             # log losses and scalar states (every N iterations)
    vis: 1000                                               # visualize results (every N iterations)
    val: 1000                                               # validate on val set (every N iterations)
    ckpt: 30000
    vis_train: 500
